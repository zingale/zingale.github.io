<!DOCTYPE HTML>
<!--
	Phase Shift by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
  <head>
    <title>Michael Zingale: Simulation Codes / Algorithms</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="description" content="" />
    <meta name="keywords" content="" />
    <!--[if lte IE 8]><script src="css/ie/html5shiv.js"></script><![endif]-->
    <script src="js/jquery.min.js"></script>
    <script src="js/jquery.dropotron.min.js"></script>
    <script src="js/skel.min.js"></script>
    <script src="js/skel-layers.min.js"></script>
    <script src="js/init.js"></script>
    <noscript>
      <link rel="stylesheet" href="css/skel.css" />
      <link rel="stylesheet" href="css/style.css" />
      <link rel="stylesheet" href="css/style-wide.css" />
    </noscript>
    <!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
  </head>
  <body>

    <!-- Wrapper -->
    <div class="wrapper style1">

      <!-- Header -->
      <div id="header" class="skel-panels-fixed">
	<div id="logo">
	  <h1><a href="../../index.html">Michael Zingale</a></h1>
	  <span class="tag">algorithms</span>
	</div>
	<nav id="nav">
	  <ul>
	    <li><a href="../../index.html">Homepage</a></li>
	    <li><a href="../../research.html">Research</a></li>
	    <li><a href="../../pub_year.html">Papers</a></li>
	    <li><a href="../../codes.html">Codes</a></li>
	  </ul>
	</nav>
      </div>
      <!-- Header -->

      <!-- Page -->
      <div id="page" class="container">
	<div class="row">

	  <!-- Sidebar -->
	  <div id="sidebar" class="4u">
	    <section>

	      <ul class="default">
		<li><h3>Simulation methodology</h3>

                  <span>Our group develops several simulation codes
                    designed to model astrophysical flows, in
                    particular, the explosive environments found in
                    stellar explosions.
                    The <a href="#amrexastro">AMReX-Astrophysics
                    suite</a> of codes is built on the adaptive mesh
                    refinement library AMReX and designed to
                    efficiently model low Mach number convection and
                    highly-compressible flows in stars.  We pay
                    particular attention to
                    the <a href="#sdc">coupling of reactions and
                    hydrodynamics</a> to ensure that we accurately
                    model stellar environments where nucleosynthesis
                    takes place, and use <a href="#gpu">performance
                    portable</a> parallelization techniques to ensures
                    that we perform well at scale on modern
                    supercomputers.
                    </span>
                </li>

                <li><h3>Support</h3>
                  <span>Supported by the DOE Office of Nuclear Physics.</span></li>

		<li><h3>Open Science</h3>
		    <span>All of our simulation codes are fully open source and
                      available on github</span> </li>
	      </ul>
	    </section>
	  </div>

	  <!-- Content -->
	  <div id="content" class="8u skel-cell-important">
	    <section>
              <a name="castro"></a>

	      <header class="major">
		<h2>AMReX-Astrophysics</h2>
	      </header>

              <p><h3 class="subsection">Castro: compressible flows</h3>

                <p>Our group develops
                the <a href="https://amrex-astro.github.io/Castro/">Castro</a>
                compressible (magneto-, radiation) hydrodynamics code.
                Castro supports a general equation of state, arbitrary
                nuclear reaction network, full self gravity w/
                isolated boundary conditions, thermal diffusion,
                flux-limited diffusion (multigroup) radiation,
                rotation, and more.

                <p>Castro runs on anything from laptops to
                supercomputers, using MPI+OpenMP for CPUs and MPI+CUDA
                for GPUs.

                <p><img class="center" src="slice_grid.png" alt="the adaptive mesh refinement grid in Castro">

                <p>We use Castro for our <a href="../wdmerger">white
                dwarf merger</a> and <a href="../xrb">X-ray burst</a>
                simulations.

              <p><h3 class="subsection">MAESTROeX: low Mach number stellar flows</h3>

                <p>We also develop (together with LBNL)
                the <a href="https://amrex-astro.github.com/MAESTROeX">MAESTROeX</a>
                low Mach number stellar hydrodynamics code.  MAESTROeX
                filters soundwaves from the equations of hydrodynamics
                while keeping compressibility effects due to
                stratification and local heat release.  This enables
                it to take large timesteps, not constrained by the
                soundspeed, for subsonic flows.

                <p>We use MAESTROeX (and its predecessor MAESTRO) for
                our <a href="../wdconvect">white dwarf
                convection</a>, <a href="../xrb">X-ray burst</a>,
                and <a href="../subchandra">sub-Chandra Type Ia
                supernovae</a> simulations.


              <a name="sdc"></a>

	      <header class="major">
		<h2>Reactive flows</h2>
	      </header>

              <p>All of our simulations involve reacting
              flows&mdash;the immense energy release from nuclear
              burning drives hydrodynamic flows.  These two processes
              need to be tightly coupled together to ensure that we
              accurately capture the dynamics and nucleosynthesis.
              The traditional method of coupling hydrodynamics and
              reactions in astrophysics has been Strang splitting, a
              type of operator splitting where the reactions and
              hydrodynamics operations each act on the state left
              behind from the other process, but there is no explicit
              coupling.  We have been developing spectral deferred
              correction (SDC) techniques to strongly couple the two
              processes.  In SDC methods, the hydrodynamics explicitly
              sees a reaction source and the reactions take into
              account how advection alters the state during the burn.
              Iteration is used to fully couple the processes.  SDC
              methods are integrated into both Castro and MAESTROeX.

                <p><img class="center" src="sdc_plot.png" alt="two timesteps comparing the SDC and Strang approaches to coupling reactions and hydrodynamics">

                  <p class="caption">Two timesteps from a Castro
                  detonation calculation, showing the helium mass
                  fraction.  The orange points show the state in the
                  SDC evolution where each point represents substep
                  used in integrating the reaction network.  By
                  coupling the advection directly to the reaction
                  evolution, we see the evolution is smooth an
                  continuous.  In the Strang case, we see the
                  reactions in the first Δt/2 of the evolution take
                  the state far from the smooth SDC solution.
                  Advection at the midpoint in time over-corrects the
                  solution, and then the final Δt/2 of reaction brings
                  us back to the SDC solution.


              <a name="gpus"></a>

	      <header class="major">
		<h2>Performance portability</h2>
	      </header>

              <p>All of our codes are written to be performance
              portable%mdash;able to run on anything from a laptop to
              a supercomputer.  Through
              the <a href="https://amrex-codes.github.io/amrex/">AMReX</a>
              library, we write our compute kernels in C++ and use
              Parallel-For loops that loop over the zones in a grid.
              On GPUs, each zone is assigned to a GPU thread, while on
              CPUs, we use logical tiling and OpenMP to distribute the
              work over processor codes.

              <p><img class="center" src="wdmerger_gpu.png" alt="GPU vs. CPU scaling for the WD merger problem">

              <p class="caption">Comparison of GPU (6 NVIDIA V100 /
              node) and CPU (42 Power9 cores / node) on the OLCF
              Summit machine for a merge white dwarf simulation
              (hydrodynamics and full self-gravity).


	    </section>
	  </div>

	</div>
      </div>
      <!-- /Page -->

    </div>
  </body>
</html>
